<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>Webbots, Crawlers and Scrapers</title>
<link href="style.css" rel="stylesheet" type="text/css" />
<link rel="shortcut icon" href="images/favicon.ico">
<link rel="icon" type="image/gif" href="images/animated_favicon1.gif">
<meta name="keywords" content="elite solutions computer service, web design, web development, freelancer, software, diagnostics, php, html, javascript, css, computer, web bots, spiders, premier, renovation, cameron anglin, applications" />
</head>

<body id="dark">
<div id="main">
  <div class="container">
    <div id="header">
      <ul id="menu">
        <li><a href="index.html">Home</a></li>
        <li><a href="design.html">Design</a></li>
        <li><a href="development.html">Development</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="contact.html">Contact</a></li>
      </ul>
      <div id="logo">
        <h1>ESCS</h1>
        <small>Elite Solutions Computer Service</small> </div>
    </div>
    <div id="robot">
    </div>
    <div id="block_content">
      <div id="content_area" class="block">
        <div class="block_inside">
          <h4>Webbots, Crawlers, and Spiders</h4>
          <h2></h2>
          <br/>
          <p>Custom webbots that can accomplish nearly any task that you can think of on the internet. Major internet companies like Google and Microsoft use them extensively to keep track of just about everything online. However, Business of all types use them to passively collect a wide variety of data. What would take employee with IT skills weeks and months to do, a webbot can do right away, in a fraction of then time. When writing webbot's, the sky's the limit. Here's a list of some of the popular uses for webbot's.</p>
          <h4></h4>
          <ul>
            <li>Image Collectors - Scour the web collecting images of a certain type and sending them back to a database.</li>
            <li>Price Monitoring - Monitor prices of items at popular sites such as eBay, and notifies and bids for you automatically.</li>
            <li>Link Verification - Useful for other developers. Traverses a given website and detects broken links.</li>
            <li>Web Mirroring - These bots download a copy of a website for offline, local analysis.</li>
            <li>Site Analyzers - Web site analyzing bots can be coded to investigate</li>
            <li>Email Collectors - Some bots simple,y scour the web looking for email addresses. They are usually targeted at specific genres of websites. Once gathered, the list can be sold to email marketing firms.</li>
          </ul>
    </div>
      </div>
      </div>
      <!-- a Clearing DIV to clear the DIV's because overflow:auto doesn't work here -->
      <div style="clear:both"></div>
    </div>
  </div>
</div>
</div>

<div id="footer">
  <div class="container">
    <div class="footer_column long">
      <h3>Elite Solutions Computer Service &copy; 2011</h3>
      <p>A computer technology company</p>
    </div>
    <div class="footer_column">
      <h3>Links</h3>
      <a href="elitesolutionscomputerservice.com/contact">Contact Me</a>
      <p>978.912.0126</p>
    </div>
  </div>
</div>
<script type="text/javascript">
	var analyticsFileTypes = [''];
	var analyticsEventTracking = 'enabled';
</script> 
<script type="text/javascript">
	var _gaq = _gaq || [];
	_gaq.push(['_setAccount', 'UA-17220244-2']);
	_gaq.push(['_trackPageview']);

	(function() {
		var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
		ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
		var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	})();
</script>
</body>
</html>
